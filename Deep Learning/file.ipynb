{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72.9998311 , 18.45119956, 34.66396944, ..., 59.26641473,\n",
       "         5.02348036, 38.55427435],\n",
       "       [78.6607336 , 34.55791865,  7.64143785, ..., 97.61667899,\n",
       "        12.18022821, 97.29338156],\n",
       "       [49.23713954,  1.34946504, 82.94170307, ..., 59.25046717,\n",
       "        13.33534032,  4.23859918],\n",
       "       ...,\n",
       "       [57.00718597, 32.29665601, 64.57675078, ..., 56.30101701,\n",
       "        31.38646064, 10.10343445],\n",
       "       [ 2.67064842,  7.87090917, 45.03529089, ..., 75.55287428,\n",
       "        36.32065713, 51.21621628],\n",
       "       [91.76175236, 19.231826  , 69.53596251, ..., 96.8940972 ,\n",
       "        46.58153813, 90.99699809]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num_row, X_num_col = [20, 200000] \n",
    "X_raw = np.random.rand(X_num_row,X_num_col) * 100\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 200000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_raw = np.concatenate(([(X_raw[0,:] + X_raw[1,:])], [(X_raw[0,:] - X_raw[1,:])], np.abs([(X_raw[0,:] - X_raw[1,:])])))\n",
    "# for input a and b, output is a+b; a-b and |a-b|\n",
    "y_num_row, y_num_col = y_raw.shape\n",
    "y_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Split train-test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.7\n",
    "num_train_datum = int(train_ratio*X_num_col)\n",
    "X_raw_train = X_raw[:,0:num_train_datum]\n",
    "X_raw_test = X_raw[:,num_train_datum:]\n",
    "\n",
    "\n",
    "y_raw_train = y_raw[:,0:num_train_datum]\n",
    "y_raw_test = y_raw[:,num_train_datum:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scaler:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "def get_scaler(row):\n",
    "    mean = np.mean(row)\n",
    "    std = np.std(row)\n",
    "    return scaler(mean, std)\n",
    "\n",
    "def standardize(data, scaler):\n",
    "    return (data - scaler.mean) / scaler.std\n",
    "\n",
    "def unstandardize(data, scaler):\n",
    "    return (data * scaler.std) + scaler.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct scalers from training set\n",
    "\n",
    "X_scalers = [get_scaler(X_raw_train[row,:]) for row in range(X_num_row)]\n",
    "X_train = np.array([standardize(X_raw_train[row,:], X_scalers[row]) for row in range(X_num_row)])\n",
    "\n",
    "y_scalers = [get_scaler(y_raw_train[row,:]) for row in range(y_num_row)]\n",
    "y_train = np.array([standardize(y_raw_train[row,:], y_scalers[row]) for row in range(y_num_row)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply those scalers to testing set\n",
    "\n",
    "X_test = np.array([standardize(X_raw_test[row,:], X_scalers[row]) for row in range(X_num_row)])\n",
    "\n",
    "y_test = np.array([standardize(y_raw_test[row,:], y_scalers[row]) for row in range(y_num_row)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.3723754775523307e-17, -8.705417339375085e-17, -4.222653972517167e-16, -4.237879888283455e-17, 1.4698084019723216e-16, -4.0267471896575965e-16, 1.0112545721442854e-16, -3.5803740924425904e-16, -1.7268726131598149e-16, -5.534620381045637e-17, -2.401951653447603e-16, -4.801238771636106e-17, 2.0174338390331416e-16, -1.4880795008918669e-16, -2.9223607660761837e-16, 7.714463988252517e-18, -3.948587488723985e-17, -9.780113227212237e-17, 2.2534355334106035e-16, -1.0531258405015771e-17]\n",
      "[1.0, 0.9999999999999999, 1.0, 1.0, 1.0, 0.9999999999999999, 1.0, 1.0, 1.0, 0.9999999999999999, 0.9999999999999999, 1.0, 1.0, 0.9999999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9999999999999999]\n",
      "[-2.0605739337042906e-16, -3.375077994860476e-17, 6.83136087380782e-17]\n",
      "[0.9999999999999999, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Check if data has been standardized\n",
    "\n",
    "print([X_train[row,:].mean() for row in range(X_num_row)]) # should be close to zero\n",
    "print([X_train[row,:].std() for row in range(X_num_row)])  # should be close to one\n",
    "\n",
    "print([y_train[row,:].mean() for row in range(y_num_row)]) # should be close to zero\n",
    "print([y_train[row,:].std() for row in range(y_num_row)])  # should be close to one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Construct a neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer:\n",
    "    def __init__(self, layer_index, is_output, input_dim, output_dim, activation):\n",
    "        self.layer_index = layer_index # zero indicates input layer\n",
    "        self.is_output = is_output # true indicates output layer, false otherwise\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.activation = activation\n",
    "        \n",
    "        # the multiplication constant is sorta arbitrary\n",
    "        if layer_index != 0:\n",
    "            self.W = np.random.randn(output_dim, input_dim) * np.sqrt(2/input_dim) \n",
    "            self.b = np.random.randn(output_dim, 1) * np.sqrt(2/input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change layers_dim to configure your own neural net!            \n",
    "layers_dim = [X_num_row, 4, 4, y_num_row] # input layer --- hidden layers --- output layers\n",
    "neural_net = []\n",
    "\n",
    "# Construct the net layer by layer\n",
    "for layer_index in range(len(layers_dim)):\n",
    "    if layer_index == 0: # if input layer\n",
    "        neural_net.append(layer(layer_index, False, 0, layers_dim[layer_index], 'irrelevant'))\n",
    "    elif layer_index+1 == len(layers_dim): # if output layer\n",
    "        neural_net.append(layer(layer_index, True, layers_dim[layer_index-1], layers_dim[layer_index], activation='linear'))\n",
    "    else: \n",
    "        neural_net.append(layer(layer_index, False, layers_dim[layer_index-1], layers_dim[layer_index], activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted number of hyperparameters: 119\n",
      "Actual number of hyperparameters: 119\n",
      "Number of data: 200000\n"
     ]
    }
   ],
   "source": [
    "# Simple check on overfitting\n",
    "\n",
    "pred_n_param = sum([(layers_dim[layer_index]+1)*layers_dim[layer_index+1] for layer_index in range(len(layers_dim)-1)])\n",
    "act_n_param = sum([neural_net[layer_index].W.size + neural_net[layer_index].b.size for layer_index in range(1,len(layers_dim))])\n",
    "print(f'Predicted number of hyperparameters: {pred_n_param}')\n",
    "print(f'Actual number of hyperparameters: {act_n_param}')\n",
    "print(f'Number of data: {X_num_col}')\n",
    "\n",
    "if act_n_param >= X_num_col:\n",
    "    raise Exception('It will overfit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Perform forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(input_, act_func):\n",
    "    if act_func == 'relu':\n",
    "        return np.maximum(input_, np.zeros(input_.shape))\n",
    "    elif act_func == 'linear':\n",
    "        return input_\n",
    "    else:\n",
    "        raise Exception('Activation function is not defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(input_vec, layers_dim=layers_dim, neural_net=neural_net):\n",
    "    neural_net[0].A = input_vec # Define A in input layer for for-loop convenience\n",
    "    for layer_index in range(1,len(layers_dim)): # W,b,Z,A are undefined in input layer\n",
    "        neural_net[layer_index].Z = np.add(np.dot(neural_net[layer_index].W, neural_net[layer_index-1].A), neural_net[layer_index].b)\n",
    "        neural_net[layer_index].A = activation(neural_net[layer_index].Z, neural_net[layer_index].activation)\n",
    "    return neural_net[layer_index].A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test run\n",
    "\n",
    "forward_prop(X_train).shape == y_train.shape # should be True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Perform back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(y, y_hat, metric='mse'):\n",
    "    if metric == 'mse':\n",
    "        individual_loss = 0.5 * (y_hat - y) ** 2\n",
    "        return np.mean([np.linalg.norm(individual_loss[:,col], 2) for col in range(individual_loss.shape[1])])\n",
    "    else:\n",
    "        raise Exception('Loss metric is not defined.')\n",
    "\n",
    "def get_dZ_from_loss(y, y_hat, metric):\n",
    "    if metric == 'mse':\n",
    "        return y_hat - y\n",
    "    else:\n",
    "        raise Exception('Loss metric is not defined.')\n",
    "\n",
    "def get_dactivation(A, act_func):\n",
    "    if act_func == 'relu':\n",
    "        return np.maximum(np.sign(A), np.zeros(A.shape)) # 1 if backward input >0, 0 otherwise; then diaganolize\n",
    "    elif act_func == 'linear':\n",
    "        return np.ones(A.shape)\n",
    "    else:\n",
    "        raise Exception('Activation function is not defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(y, y_hat, metric='mse', layers_dim=layers_dim, neural_net=neural_net, num_train_datum=num_train_datum):\n",
    "    for layer_index in range(len(layers_dim)-1,0,-1):\n",
    "        if layer_index+1 == len(layers_dim): # if output layer\n",
    "            dZ = get_dZ_from_loss(y, y_hat, metric)\n",
    "        else: \n",
    "            dZ = np.multiply(np.dot(neural_net[layer_index+1].W.T, dZ), \n",
    "                             get_dactivation(neural_net[layer_index].A, neural_net[layer_index].activation))\n",
    "        dW = np.dot(dZ, neural_net[layer_index-1].A.T) / num_train_datum\n",
    "        db = np.sum(dZ, axis=1, keepdims=True) / num_train_datum\n",
    "        \n",
    "        neural_net[layer_index].dW = dW\n",
    "        neural_net[layer_index].db = db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Optimize Iteratively (Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "max_epoch = 100\n",
    "\n",
    "for epoch in range(1,max_epoch+1):\n",
    "    y_hat_train = forward_prop(X_train) # update y_hat\n",
    "    backward_prop(y_train, y_hat_train) # update (dW,db)\n",
    "    \n",
    "    for layer_index in range(1,len(layers_dim)):        # update (W,b)\n",
    "        neural_net[layer_index].W = neural_net[layer_index].W - learning_rate * neural_net[layer_index].dW\n",
    "        neural_net[layer_index].b = neural_net[layer_index].b - learning_rate * neural_net[layer_index].db\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f'{get_loss(y_train, y_hat_train):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001906167593345958"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test loss\n",
    "\n",
    "get_loss(y_test, forward_prop(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_raw_any):\n",
    "    X_any = np.array([standardize(X_raw_any[row,:], X_scalers[row]) for row in range(X_num_row)])\n",
    "    y_hat = forward_prop(X_any)\n",
    "    y_hat_any = np.array([unstandardize(y_hat[row,:], y_scalers[row]) for row in range(y_num_row)])\n",
    "    return y_hat_any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04810509, 2.81607135, 1.83828312],\n",
       "       [1.51309246, 0.71426828, 0.73804594],\n",
       "       [2.38758705, 1.59214111, 1.61800985]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(y_test.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb4a0ac80907d7f44e1a5e88d3d3381b33e3dbedd3a24d113e876f30a0c46bee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
